import requests
import os
import argparse
from pathlib import Path
import openai
import markdown2  # âœ… HTML ë³€í™˜ìš©
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import re
import pyperclip
from selenium.webdriver.common.keys import Keys
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë”©
load_dotenv("my_key.env")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
MAKER_EMAIL = os.getenv("MAKER_EMAIL")
MAKER_PASSWORD = os.getenv("MAKER_PASSWORD")
GITHUB_OWNER = os.getenv("GITHUB_OWNER")
GITHUB_REPO = os.getenv("GITHUB_REPO")
OUTPUT_NAME = os.getenv("OUTPUT_NAME")
TSG_FILE_NAME = os.getenv("TSG_FILE_NAME", "troubleshooting_guide.md")
TODO_FILE_NAME = os.getenv("TODO_FILE_NAME", "ToDolist.md")


def remove_bullet_and_numbering(text):
    cleaned_lines = []
    for line in text.splitlines():
        stripped = line.strip()
        # 1. ë˜ëŠ” - ë˜ëŠ” * ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ ì œê±°
        if re.match(r"^(\d+\.|- |\* )", stripped):
            # ìˆ«ì ê¸€ë¨¸ë¦¬ë‚˜ ê¸°í˜¸ ì œê±°
            cleaned_line = re.sub(r"^(\d+\.\s+|- |\* )", "", line)
            cleaned_lines.append(cleaned_line)
        else:
            cleaned_lines.append(line)
    return "\n".join(cleaned_lines)

# âœ… ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜
def markdown_to_html(md_text):
    return markdown2.markdown(md_text)

# ì´ìŠˆ ë‚´ìš© ìš”ì•½ (í•„ìš”ì— ë”°ë¼ OpenAI ì‚¬ìš©)
def analyze_issue_text(text):
    prompt = f"""
Below is the body of a GitHub issue. The purpose is to analyze the problem phenomenon, cause, and solution from this content and create a troubleshooting guide that can be provided to customers experiencing the same issue. Please read this text and organize it only in English as follows:

## Problem Phenomenon (The issue):
## Cause (The cause of the issue):
## Solution (Concrete code changes, configuration changes, step-by-step actions, etc., that actually solved the problem):

--- Start of Issue Content ---
{text}
--- End of Issue Content ---
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ OpenAI Analysis Failed: {e}")
        return "Problem: Analysis failed\nCause: Analysis failed\nSolution: Analysis failed"

def extract_todo_from_issue(text):
    prompt = f"""
Below is a GitHub issue discussion (including body and comments).
Your task is to determine whether there is any feature request or technical requirement that represents a new capability, significant functional enhancement, or integration demand which WIZnet (a network solution provider) could support or address.

Ignore minor code cleanups, bug fix suggestions, or cosmetic refactoring.

Focus only on substantive feature requests or technical needs (e.g., non-blocking APIs, new protocol support, architecture compatibility, etc.).

If such a request exists:

Extract the core feature request or technical suggestion in English (summarized).

Provide a brief background explanation of what this request implies or why it's needed.

If not, return "NONE".

--- GitHub Issue Content ---
{text}
--- End of Content ---
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=300
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ OpenAI ToDo ë¶„ì„ ì‹¤íŒ¨: {e}")
        return "NONE"


# GitHub APIë¡œ Closed ì´ìŠˆ ê°€ì ¸ì˜¤ê¸°
def get_closed_issues(owner, repo, token):
    issues = []
    page = 1
    headers = {"Authorization": f"token {token}"}
    while True:
        params = {"state": "closed", "per_page": 100, "page": page}
        response = requests.get(
            f"https://api.github.com/repos/{owner}/{repo}/issues",
            headers=headers,
            params=params
        )
        if response.status_code != 200:
            raise Exception(f"GitHub API Error: {response.status_code} - {response.text}")
        data = response.json()
        if not data:
            break
        for issue in data:
            if "pull_request" not in issue:  # PR ì œì™¸
                issues.append(issue)
        page += 1
    return issues

def get_open_issues(owner, repo, token):
    issues = []
    page = 1
    headers = {"Authorization": f"token {token}"}
    while True:
        params = {"state": "open", "per_page": 100, "page": page}
        response = requests.get(
            f"https://api.github.com/repos/{owner}/{repo}/issues",
            headers=headers,
            params=params
        )
        if response.status_code != 200:
            raise Exception(f"GitHub API Error (Open Issues): {response.status_code} - {response.text}")
        data = response.json()
        if not data:
            break
        for issue in data:
            if "pull_request" not in issue:  # PR ì œì™¸
                issues.append(issue)
        page += 1
    return issues

# íŠ¹ì • ì´ìŠˆì— ëŒ€í•œ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°
def get_issue_comments(owner, repo, issue_number, token):
    comments = []
    page = 1
    headers = {"Authorization": f"token {token}"}
    while True:
        url = f"https://api.github.com/repos/{owner}/{repo}/issues/{issue_number}/comments"
        params = {"per_page": 100, "page": page}
        response = requests.get(url, headers=headers, params=params)
        if response.status_code != 200:
            raise Exception(f"GitHub API Error (Comments): {response.status_code} - {response.text}")
        data = response.json()
        if not data:
            break
        for comment in data:
            comments.append(comment.get("body", ""))
        page += 1
    return comments


# ë§ˆí¬ë‹¤ìš´ í¬ë§·
def format_issue_markdown(issue, comments=None):
    title = issue.get("title", "ì œëª© ì—†ìŒ")
    body_raw = issue.get("body", "")
    body = body_raw.strip().replace("''", "'")
    url = issue.get("html_url")

    comments_md = ""
    if comments:
        for idx, comment in enumerate(comments, 1):
            comments_md += f"\n**ğŸ’¬ Comment {idx}:**\n{comment}\n"

    summary = body + comments_md
    summary = analyze_issue_text(summary)

    md_result = f"""# [Title] {title}

{summary}

[View GitHub Issue]({url})

"""
    html_result = markdown_to_html(md_result)
    return md_result, html_result, title

# ê¸°ì¡´ ì´ìŠˆ URL ìˆ˜ì§‘
def get_existing_issue_urls(filepath):
    if not filepath.exists():
        return set()
    with filepath.open(encoding="utf-8") as f:
        lines = f.readlines()
    return {line.strip().split("(")[-1].rstrip(")\n") for line in lines if line.startswith("[GitHub ì´ìŠˆ ë³´ê¸°]")}

def get_existing_todo_urls(filepath):
    if not Path(filepath).exists():
        return set()
    with open(filepath, encoding="utf-8") as f:
        content = f.read()
    return set(re.findall(r"\[View Issue\]\((https://github\.com/.+?)\)", content))

def append_open_issues_to_todolist(issues, owner, repo, token, output_path="ToDolist.md"):
    existing_urls = get_existing_todo_urls(output_path)
    new_entries = []
    for issue in issues:
        issue_number = issue.get("number")
        issue_url = issue.get("html_url")

        if issue_url in existing_urls:
            continue  # ì¤‘ë³µ ë°©ì§€

        title = issue.get("title")
        body = issue.get("body", "")
        comments = get_issue_comments(owner, repo, issue_number, token)
        full_text = f"{body}\n" + "\n".join(comments)
        
        summary = extract_todo_from_issue(full_text)
        if summary != "NONE":
            md = f"""### {title}

- **Suggestion**: {summary}  
- [View Issue]({issue_url})  

"""
            new_entries.append(md)

    if not new_entries:
        print("ğŸŸ¢ Open ì´ìŠˆ ì¤‘ ëŒ€ì‘í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(output_path, "a", encoding="utf-8") as f:
        for entry in new_entries:
            f.write(entry + "\n")

    print(f"âœ… {len(new_entries)}ê°œ í•­ëª©ì´ ToDolist.mdì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")


def append_issues_to_md_and_upload(issues, md_path, existing_urls, owner, repo, token):
    new_entries = []
    for issue in issues:
        url = issue.get("html_url")
        if url not in existing_urls:
            issue_number = issue.get("number")
            comments = get_issue_comments(owner, repo, issue_number, token)
            md, html, title = format_issue_markdown(issue, comments)
            new_entries.append((md, html, title))

    if not new_entries:
        print("ğŸŸ¢ ì¶”ê°€í•  ìƒˆë¡œìš´ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(md_path, "a", encoding="utf-8") as f:
        for md, html, title in new_entries:
            f.write(md + "\n")

    print(f"âœ… {len(new_entries)}ê°œì˜ ì´ìŠˆë¥¼ Markdown ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

def input_text_with_send_keys(element, text, chunk_size=300):
    for i in range(0, len(text), chunk_size):
        chunk = text[i:i+chunk_size]
        element.send_keys(chunk)
        time.sleep(0.1)  # ë„ˆë¬´ ë¹ ë¥´ë©´ ëˆ„ë½ë  ìˆ˜ ìˆì–´ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€


def paste_text_using_clipboard(element, text):
    pyperclip.copy(text)  # í…ìŠ¤íŠ¸ë¥¼ í´ë¦½ë³´ë“œì— ë³µì‚¬
    element.click()       # ì—ë””í„° í™œì„±í™”
    time.sleep(0.5)
    element.send_keys(Keys.CONTROL, 'v')  # ë¶™ì—¬ë„£ê¸° (Macì€ COMMANDë¡œ ë³€ê²½)
    time.sleep(1)  # ë¶™ì—¬ë„£ê¸° ì™„ë£Œê¹Œì§€ ëŒ€ê¸°

def upload_full_issue_list(repo_name, all_text):
    driver = webdriver.Chrome()
    driver.get("https://maker.wiznet.io/forum")
    driver.maximize_window()

    # ë¡œê·¸ì¸
    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, "layLoginBtn"))).click()
    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, "loginFrm")))
    time.sleep(0.5)
    #driver.execute_script("""
    #    document.querySelector("input[name='email']").value = "{MAKER_EMAIL}";
    #    document.querySelector("input[name='pass']").value = "{MAKER_PASSWORD}";
    #""")
    driver.execute_script(f"""
        document.querySelector("input[name='email']").value = "{MAKER_EMAIL}";
        document.querySelector("input[name='pass']").value = "{MAKER_PASSWORD}";
    """)
    time.sleep(0.3)
    driver.find_element(By.CLASS_NAME, "loginBtn").click()
    print("âœ… ë¡œê·¸ì¸ ì™„ë£Œ")

    time.sleep(1)
    driver.get("https://maker.wiznet.io/forum/write")
    time.sleep(1)

    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, "btn_addProject"))).click()
    time.sleep(1)

    # ì œëª© ì…ë ¥: <repo ì´ë¦„> issue list
    driver.find_element(By.ID, "inputSubject").send_keys(f"{repo_name} issue list")
    time.sleep(1)

    driver.find_element(By.ID, "categoryTrigger").click()
    time.sleep(1)
    driver.find_element(By.CSS_SELECTOR, "#categorySelector button[data-idx='18']").click()
    time.sleep(1)

    # ë³¸ë¬¸ ì…ë ¥
    editor_div = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, ".ck-editor__main div[contenteditable='true']"))
    )
    driver.execute_script("arguments[0].focus();", editor_div)
    paste_text_using_clipboard(editor_div, all_text)

    time.sleep(3)

    # reCAPTCHA ìˆ˜ë™ ì²˜ë¦¬ ì•ˆë‚´
    iframe = driver.find_element(By.CSS_SELECTOR, "iframe[title*='reCAPTCHA']")
    driver.switch_to.frame(iframe)
    print("ğŸ›‘ reCAPTCHA ìˆ˜ë™ ì²˜ë¦¬ í•„ìš”")
    time.sleep(3)
    input("ğŸ›‘ ìˆ˜ë™ ì¸ì¦ í›„ Enter í‚¤ë¥¼ ëˆŒëŸ¬ ê²Œì‹œ ì™„ë£Œ...")


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    parser = argparse.ArgumentParser(description="GitHub Closed ì´ìŠˆ ë¶„ì„ + Maker ê²Œì‹œ ìë™í™”")
    parser.add_argument("--upload-only", action="store_true", help="ê¸°ì¡´ Markdown íŒŒì¼ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ Makerì—ë§Œ ì—…ë¡œë“œ")
    parser.add_argument("--todo", action="store_true", help="Open ìƒíƒœ ì´ìŠˆë¥¼ ë¶„ì„í•˜ì—¬ ToDolist.mdì— ê¸°ë¡")
    args = parser.parse_args()

    # ëª…ë ¹ì–´ ëª¨ë“œ ì„¤ì • (í•„ìš”ì‹œ)
    upload_only = False
    analyze_open = False

    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    global client
    client = openai.OpenAI(api_key=OPENAI_API_KEY)

    md_path = Path(TSG_FILE_NAME)

    if args.upload_only:
        if not md_path.exists():
            print(f"âŒ Markdown íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.output}")
            return

        print(f"ğŸ“„ {TSG_FILE_NAME} íŒŒì¼ì„ ì½ê³  Makerì— ì´ìŠˆë¥¼ í†µí•© ê²Œì‹œí•©ë‹ˆë‹¤...")

        with md_path.open("r", encoding="utf-8") as f:
            contents = f.read()

        issue_blocks = contents.split("# [Title] ")[1:]
        merged_md = ""
        for block in issue_blocks:
            title_end = block.find("\n")
            title = block[:title_end].strip()
            md_text = "# [Title] " + block.strip()
            cleaned = remove_bullet_and_numbering(md_text)
            merged_md += cleaned + "\n\n"

        upload_full_issue_list(GITHUB_REPO, merged_md)
        print(f"âœ… ì €ì¥ì†Œì˜ ëª¨ë“  ì´ìŠˆë¥¼ Maker í¬ëŸ¼ì— ì—…ë¡œë“œ ì™„ë£Œ.")
        return
    
    if args.todo:
        print("ğŸ§­ Open ì´ìŠˆ ì¤‘ ìš”ì²­ì‚¬í•­ ë¶„ì„ ì¤‘...")
        open_issues = get_open_issues(GITHUB_OWNER, GITHUB_REPO, GITHUB_TOKEN)
        append_open_issues_to_todolist(open_issues, GITHUB_OWNER, GITHUB_REPO, GITHUB_TOKEN, TODO_FILE_NAME)
        return

    # ê¸°ì¡´ ë¡œì§ (GitHub ì´ìŠˆë¥¼ ìƒˆë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ê²½ìš°)
    existing_urls = get_existing_issue_urls(md_path)
    print("ğŸ“¥ ê¸°ì¡´ Markdown íŒŒì¼ì—ì„œ URL ìˆ˜ì§‘ ì™„ë£Œ")

    issues = get_closed_issues(GITHUB_OWNER, GITHUB_REPO, GITHUB_TOKEN)
    print(f"ğŸ“¦ ì´ {len(issues)}ê°œì˜ Closed ì´ìŠˆë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤")

    append_issues_to_md_and_upload(issues, md_path, existing_urls, GITHUB_OWNER, GITHUB_REPO, GITHUB_TOKEN)

    if not md_path.exists():
        print(f"âŒ Markdown íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.output}")
        return

    #print(f"ğŸ“„ {args.output} íŒŒì¼ì„ ì½ê³  Makerì— ì´ìŠˆë¥¼ í†µí•© ê²Œì‹œí•©ë‹ˆë‹¤...")

    with md_path.open("r", encoding="utf-8") as f:
        contents = f.read()

    issue_blocks = contents.split("# [Title] ")[1:]
    merged_md = ""
    for block in issue_blocks:
        title_end = block.find("\n")
        title = block[:title_end].strip()
        md_text = "# [Title] " + block.strip()
        cleaned = remove_bullet_and_numbering(md_text)
        merged_md += cleaned + "\n\n"

    upload_full_issue_list(GITHUB_REPO, merged_md)
    print(f"âœ… {GITHUB_REPO} ì €ì¥ì†Œì˜ ëª¨ë“  ì´ìŠˆë¥¼ Maker í¬ëŸ¼ì— ì—…ë¡œë“œ ì™„ë£Œ.")


if __name__ == "__main__":
    main()